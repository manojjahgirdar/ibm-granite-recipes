{"cells": [{"metadata": {}, "id": "7b3918f0", "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Use watsonx.ai and LangChain Agents to perform E-commerce Analytics"}, {"metadata": {}, "id": "16529830", "cell_type": "markdown", "source": "<img src=\"https://github.com/user-attachments/assets/66ba8ea8-6481-41c6-aeaa-9a952574236e\" width=50%></img>"}, {"metadata": {}, "id": "9d0f0439", "cell_type": "markdown", "source": "#### Disclaimers\n\n- Use only Projects and Spaces that are available in watsonx context.\n\n\n## Notebook content\n\nThis notebook contains the steps and code to demonstrate usage of LangChain Agents with watsonx.ai models.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n\n## Learning goal\n\nThe purpose of this notebook is to demonstrate how to use large language models, e.g. `mistralai/mistral-large`, to create Structured Chat LangChain Agent with memory, where an Agent may perform sequence of actions based on the model reasoning and assures that LLM uses chat memory to provide the most accurate answer on the user question. The Agent can also use various tools such as SQL or RAG retriever to get the relevant information from structured data sources such as SQL tables or unstrustured data sources such as Vectorstore. \n\n\n## Contents\n\nThis notebook contains the following parts:\n\n- [Pre requisites](#)\n- [Setup](#setup)\n- [LangChain integration](#watsonxllm)\n- [Data Preparation](#data_preparation)\n- [Prompt template and custom tools](#prompt_template)\n- [LangChain Agent](#agent)\n- [Example of Structured Chat](#chat)\n- [Summary](#summary)"}, {"metadata": {}, "id": "52db93e1", "cell_type": "markdown", "source": "<a id=\"pre_requisites\"></a>\n## Pre requisites\n\nYou need to have a Db2 Database as a pre-requisite. Create tables in the Db2 Database with the ecommerce datasets provided in the watsonx project. Your Db2 should have these tables:\n\n- customer_purchase_history\n- product_inventory\n- sales_data"}, {"metadata": {}, "id": "0a3cf8be", "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watson-machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."}, {"metadata": {}, "id": "d775be1a", "cell_type": "markdown", "source": "### Install and import the `datasets` and dependecies"}, {"metadata": {}, "id": "e9f0b3e6", "cell_type": "code", "source": "!pip install -U \"ibm-watsonx-ai==1.1.2\" | tail -n 1\n!pip install -U \"pydantic==2.8.2\" | tail -n 1\n!pip install -U \"langchain==0.2.12\" | tail -n 1\n!pip install -U \"langchain-ibm==0.1.11\" | tail -n 1\n!pip install -U \"langchain-core==0.2.28\" | tail -n 1\n!pip install -U \"langchain-community==0.2.11\" | tail -n 1\n!pip install -U \"langchain_huggingface==0.0.3\" | tail -n 1\n!pip install -U \"sqlalchemy==1.4.47\" | tail -n 1\n!pip install -U \"pymilvus==2.4.4\" | tail -n 1\n!pip install -U \"PyMuPDF==1.24.9\" | tail -n 1", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "af3f6087", "cell_type": "markdown", "source": "**Note: Restart the kernel after installing the dependencies** "}, {"metadata": {}, "id": "9248b071", "cell_type": "markdown", "source": "### Defining the WML credentials\nThis cell defines the WML credentials required to work with watsonx Foundation Model inferencing.\n\n**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."}, {"metadata": {}, "id": "2ddb2bff", "cell_type": "code", "source": "import getpass\n\ncredentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n}", "execution_count": 1, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Please enter your WML api key (hit enter): \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}]}, {"metadata": {}, "id": "004bd8f1", "cell_type": "markdown", "source": "### Defining the project id\nThe Foundation Model requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id."}, {"metadata": {}, "id": "58cfda34", "cell_type": "code", "source": "import os\n\ntry:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")", "execution_count": 2, "outputs": []}, {"metadata": {}, "id": "bd9304f9", "cell_type": "markdown", "source": "<a id=\"watsonxllm\"></a>\n## Initialize `WatsonxLLM` instance"}, {"metadata": {}, "id": "2e4685e4", "cell_type": "markdown", "source": "#### Set model parameters\n\nTo set the model parameters we use `GenTextParamsMetaNames` metanames from `ibm-watsonx-ai`."}, {"metadata": {}, "id": "0d831d54", "cell_type": "code", "source": "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\nfrom langchain_ibm import WatsonxLLM", "execution_count": 3, "outputs": []}, {"metadata": {}, "id": "b5055df4", "cell_type": "markdown", "source": "Based on the performed experiments we found that the following parameters work well with the LangChain Agents created in the further section."}, {"metadata": {}, "id": "328e807c", "cell_type": "code", "source": "parameters = {\n    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n    GenTextParamsMetaNames.MIN_NEW_TOKENS: 20,\n    GenTextParamsMetaNames.DECODING_METHOD: 'greedy',\n}", "execution_count": 4, "outputs": []}, {"metadata": {}, "id": "e0bee246", "cell_type": "markdown", "source": "Furthermore, you need to specify `model_id` that will be used for inferencing. In the following notebook we use `mistralai/mistral-large`."}, {"metadata": {}, "id": "2c6aa042", "cell_type": "markdown", "source": "Based on the performed experiments we found that the following models work well with LangChain Agents:\n\n- mistralai/mistral-large\n- meta-llama/llama-3-405b-instruct\n- meta-llama/llama-3-70b-instruct\n- meta-llama/llama-2-70b-chat\n- mistralai/mixtral-8x7b-instruct-v01"}, {"metadata": {}, "id": "c26cf4bf", "cell_type": "code", "source": "llm = WatsonxLLM(\n    url=credentials.get('url'),\n    apikey=credentials.get('apikey'),\n    project_id=project_id,\n    model_id=\"mistralai/mistral-large\",\n    params=parameters\n)", "execution_count": 5, "outputs": []}, {"metadata": {}, "id": "80b00852", "cell_type": "markdown", "source": "#### Test the model"}, {"metadata": {}, "id": "b88c2f56", "cell_type": "code", "source": "response = llm.invoke('What is a generative AI? Respond concisely.')\nprint(response)", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "\n\nGenerative AI is a type of artificial intelligence that creates new content, such as images, music, or text. It learns patterns from input data and generates new, likely outputs. Examples include DALL-E for images and ChatGPT for text.\n", "name": "stdout"}]}, {"metadata": {}, "id": "42926091", "cell_type": "markdown", "source": "<a id=\"data_preparation\"></a>\n## Data Preparation\n### Create SQL Tables"}, {"metadata": {}, "id": "df9b41ae", "cell_type": "markdown", "source": "In this section we load the structured data into SQL tables.\n\n- **Structured data**: SQL Database with three tables\n  - **Sales Data**\n  - **Product Inventory**\n  - **Customer Purchase History**"}, {"metadata": {}, "id": "820e5eda", "cell_type": "code", "source": "import pandas as pd\nimport sqlalchemy\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine import URL\nimport ibm_db\nimport ibm_db_sa\nfrom langchain.sql_database import SQLDatabase\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit", "execution_count": 7, "outputs": []}, {"metadata": {}, "id": "83f1c3da", "cell_type": "code", "source": "import contextlib\nfrom tempfile import TemporaryFile\nfrom tabulate import tabulate\nimport os", "execution_count": 8, "outputs": []}, {"metadata": {}, "id": "beb18122", "cell_type": "markdown", "source": "### Add your Db2 Credentials in the cell below"}, {"metadata": {}, "id": "12b52b5a", "cell_type": "code", "source": "@contextlib.contextmanager\ndef get_ecommerce_db():\n    # Define your database connection parameters\n    user = \"\"\n    pwd = \"\"\n    host = \"\"\n    port = \"\"\n    db_name = \"bludb\"\n    \n    connection_string = f'db2://{user}:{pwd}@{host}:{port}/{db_name};SECURITY=SSL;PROTOCOL=TCPIP;'\n    \n    # Create the SQLAlchemy engine\n    engine = None\n    try:\n        engine = create_engine(connection_string)\n        \n        # Initialize the SQLDatabase object\n        db = SQLDatabase(engine)\n        yield db\n\n    except SQLAlchemyError as e:\n        print(f\"An error occurred while connecting to the database: {e}\")\n        yield None\n\n    finally:\n        if engine:\n            # Ensure the engine is disposed of properly\n            engine.dispose()", "execution_count": 9, "outputs": []}, {"metadata": {}, "id": "017970ed", "cell_type": "markdown", "source": "### Create Vectorstore"}, {"metadata": {}, "id": "1aac2fee", "cell_type": "markdown", "source": "In this section we load the unstructured data into vectorstore.\n\n- **Unstructured data**: Text file with two sections\n  -  **Customer Reviews**\n  -  **Social Media Mentions**"}, {"metadata": {}, "id": "ba769c3c", "cell_type": "markdown", "source": "### Add data from watsonx project \n\n1. Click on the below cell to bring the cursor to the cell.\n1. Click on the **Code Snippets** button on top right corner of the watson studio.\n1. Click on **Select data from project**.\n1. Select the category as **Data asset** and select the **reviews.txt** file.\n1. Select the load as **StreamingBody object** and click on **Insert code to cell**"}, {"metadata": {}, "id": "12803fda", "cell_type": "code", "source": "# Add review.txt streaming body object here", "execution_count": 10, "outputs": []}, {"metadata": {}, "id": "a1f42782", "cell_type": "markdown", "source": ">Note: Make sure the streaming body variable name is `streaming_body_1`"}, {"metadata": {}, "id": "cd25a090", "cell_type": "code", "source": "file_text = streaming_body_1.read().decode('utf-8')", "execution_count": 11, "outputs": []}, {"metadata": {}, "id": "5d738ad2", "cell_type": "code", "source": "with open('reviews.txt', 'w') as ffile:\n    ffile.write(file_text)", "execution_count": 12, "outputs": []}, {"metadata": {}, "id": "7b3d34f6", "cell_type": "markdown", "source": "<a id=\"Define RAG Pipeline\"></a>\n## Define RAG Pipeline\n### Load, Split, Embedd, Create collection"}, {"metadata": {}, "id": "23c6c541", "cell_type": "code", "source": "from langchain_community.document_loaders import TextLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom tqdm import tqdm", "execution_count": 13, "outputs": []}, {"metadata": {}, "id": "00583eef", "cell_type": "code", "source": "from pymilvus import MilvusClient", "execution_count": 14, "outputs": []}, {"metadata": {}, "id": "06ea9900", "cell_type": "code", "source": "def rag_load(collection_name) -> MilvusClient:\n    loader = TextLoader('reviews.txt')\n    docs = loader.load()\n    print(\"Number of pages:\", len(docs))\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, is_separator_regex = False)\n    splits = text_splitter.split_documents(docs)\n    print(\"Number of splits:\", len(splits))\n    milvus_client = MilvusClient(\"./milvus_rag.db\")\n    if milvus_client.has_collection(collection_name):\n        milvus_client.drop_collection(collection_name)\n    milvus_client.create_collection(\n        collection_name=collection_name,\n        dimension=768,\n        metric_type=\"IP\",  # Inner product distance\n        consistency_level=\"Strong\",  # Strong consistency level\n    )\n    data = []\n    for i, line in enumerate(tqdm(splits, desc=\"Creating embeddings please wait...\")):\n        data.append({\"id\": i, \"vector\": embeddings.embed_query(line.page_content), \"text\": line.page_content})\n    milvus_client.insert(collection_name=collection_name, data=data)\n    return milvus_client", "execution_count": 15, "outputs": []}, {"metadata": {}, "id": "9a6fd103", "cell_type": "code", "source": "from langchain_huggingface import HuggingFaceEmbeddings", "execution_count": 16, "outputs": []}, {"metadata": {}, "id": "15755c0f", "cell_type": "code", "source": "embeddings = HuggingFaceEmbeddings()\ncollection_name = 'my_rag_collection'\nmilvus_client = rag_load(collection_name)", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8dc9c755b144436d96fa5e5a69feaf2d"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6cf9ec52874847829a958f9bad7cfdd1"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ef6313e01941460bbfc49e7fe02f7ade"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5f65aed26f834029a2a4909a93cf7b3a"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0cbb3ad2c48e46ca9a9eee3b7796fb69"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "949b45a5eb374c3c815840741044f043"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0112efed3f3144879cad791470059aca"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4bc2f961f2154f788c66cafac7aa737c"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f6b3cbb2816940fb8134f6ee900fec30"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f7486e16068640b08b581d76ad10fc23"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7b4d09b42d1e404eafc35dc99aecdecb"}}, "metadata": {}}, {"output_type": "stream", "text": "Number of pages: 1\nNumber of splits: 4\n", "name": "stdout"}, {"output_type": "stream", "text": "Creating embeddings please wait...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:01<00:00,  2.18it/s]\n", "name": "stderr"}]}, {"metadata": {}, "id": "a904e634", "cell_type": "markdown", "source": "### Create Retriever"}, {"metadata": {}, "id": "f6c96482", "cell_type": "code", "source": "def rag_retriever(query: str) -> str:\n    result = \"\"\n    search_res = milvus_client.search(\n        collection_name=collection_name,\n        data=[\n            embeddings.embed_query(query)\n        ],\n        limit=2,\n        search_params={\"metric_type\": \"IP\", \"params\": {}},\n        output_fields=[\"text\"],\n    )\n    retrieved_lines_with_distances = [\n        (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n    ]\n    for item in retrieved_lines_with_distances:\n        result += \"[Document]\\n\"\n        result += item[0] + \"\\n\"\n        result += \"[End]\\n\\n\"\n    return result.strip()", "execution_count": 18, "outputs": []}, {"metadata": {}, "id": "7ba6f5e4", "cell_type": "markdown", "source": "#### Test RAG Retriever "}, {"metadata": {"scrolled": true}, "id": "47b00c2d", "cell_type": "code", "source": "print(rag_retriever(\"What are the customer reviews?\"))", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "[Document]\n## Customer Reviews\n\nReviewID: R001\nText: \"The iPhone is fantastic! Great build quality and very useful.\"\nProductID: P001\nSentiment: Positive\nName: Alice\n\nReviewID: R002\nText: \"The iPad is okay, but a bit overpriced for what it offers.\"\nProductID: P002\nSentiment: Neutral\nName: Bob\n\nReviewID: R003\nText: \"The Mac exceeded my expectations. Highly recommend it!\"\nProductID: P003\nSentiment: Positive\nName: Charlie\n\nReviewID: R004\nText: \"The AirPods are not as good as I expected. They broke after a week.\"\nProductID: P004\nSentiment: Negative\nName: Alice\n\nReviewID: R005\nText: \"The iPhone is great, but could be a bit cheaper.\"\nProductID: P001\nSentiment: Positive\nName: David\n\nReviewID: R006\nText: \"The iPad is very useful for my daily tasks.\"\nProductID: P002\nSentiment: Positive\nName: Bob\n\nReviewID: R007\nText: \"The Mac is simply the best computer I have ever used.\"\nProductID: P003\nSentiment: Positive\nName: Charlie\n[End]\n\n[Document]\nReviewID: R007\nText: \"The Mac is simply the best computer I have ever used.\"\nProductID: P003\nSentiment: Positive\nName: Charlie\n\nReviewID: R008\nText: \"The AirPods are decent, but I had some connectivity issues.\"\nProductID: P004\nSentiment: Neutral\nName: Alice\n\nReviewID: R009\nText: \"The iPhone is worth every penny.\"\nProductID: P001\nSentiment: Positive\nName: Eve\n\nReviewID: R010\nText: \"The iPad is good, but the battery life could be better.\"\nProductID: P002\nSentiment: Neutral\nName: Frank\n\n## Social Media Mentions\n\nMentionID: M001\nText: \"Loving my new iPhone! #apple #tech\"\nProductID: P001\nPlatform: Twitter\nName: Alice\n\nMentionID: M002\nText: \"iPad is useful, but not worth the price. #reviews\"\nProductID: P002\nPlatform: Twitter\nName: Bob\n\nMentionID: M003\nText: \"Just got the new Mac, and it's amazing! #apple #computers\"\nProductID: P003\nPlatform: Instagram\nName: Charlie\n[End]\n", "name": "stdout"}]}, {"metadata": {}, "id": "f1cbebe8", "cell_type": "markdown", "source": "<a id=\"prompt_template\"></a>\n## Prompt template preparation and tools\n### Create Prompt Template"}, {"metadata": {}, "id": "12db174e", "cell_type": "markdown", "source": "A structured chat prompt template is composed of several sections: system prompt, chat history and user input. The following prompt template was prepared based on the LangChain [documentation](https://python.langchain.com/docs/modules/agents/agent_types/structured_chat) and adjusted to work with the chat models available on watsonx.ai."}, {"metadata": {}, "id": "3dbec234", "cell_type": "code", "source": "from langchain.prompts import ChatPromptTemplate\nfrom langchain.prompts.chat import MessagesPlaceholder", "execution_count": 20, "outputs": []}, {"metadata": {}, "id": "54faa78f", "cell_type": "code", "source": "system_prompt = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n{tools}\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\nValid \"action\" values: \"Final Answer\" or {tool_names}\nProvide only ONE action per $JSON_BLOB, as shown:\n```\n{{\n  \"action\": $TOOL_NAME,\n  \"action_input\": $INPUT\n}}\n```\nFollow this format:\nQuestion: input question to answer\nThought: consider previous and subsequent steps\nAction:\n```\n$JSON_BLOB\n```\nObservation: action result\n... (repeat Thought/Action/Observation N times)\nThought: I know what to respond\nAction:\n```\n{{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Final response to human\"\n}}\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action.\nRespond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation.\nReminder to ALWAYS respond with a valid JSON blob of a single action. Use tools only if necessary.\nReminder to ALWAYS list the available tables before executing any SQL query on a table.\nReminder to ALWAYS check for relationship between tables if column name is not found.\n\"\"\"", "execution_count": 21, "outputs": []}, {"metadata": {}, "id": "d2ba72ab", "cell_type": "code", "source": "user_prompt = \"\"\"{input}\n{agent_scratchpad}\n(reminder to respond in a JSON blob no matter what)\"\"\"", "execution_count": 22, "outputs": []}, {"metadata": {}, "id": "2b04958d", "cell_type": "markdown", "source": "To create the final structured chat prompt template one can use initialization class method from `ChatPromptTemplate` ."}, {"metadata": {}, "id": "7e91b167", "cell_type": "code", "source": "prompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\", system_prompt\n        ),\n        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n        (\"user\", user_prompt),\n    ]\n)", "execution_count": 23, "outputs": []}, {"metadata": {}, "id": "8e20978c", "cell_type": "markdown", "source": "### Prepare tools"}, {"metadata": {}, "id": "0b44ec4f", "cell_type": "markdown", "source": "In this section we prepare tools (python functions) that the AI assistant will have access to."}, {"metadata": {}, "id": "5950d6ff", "cell_type": "code", "source": "from langchain.agents import tool\nfrom langchain.tools import Tool", "execution_count": 24, "outputs": []}, {"metadata": {}, "id": "05268918", "cell_type": "code", "source": "@tool(\"milvus_retriever\")\ndef milvus_retriever(query: str) -> str:\n    \"\"\"\n    Returns the matching occurance of the query from the vectorstore.\n\n    Args:\n        query: The query string to match in the vectorstore.\n\n    Returns:\n        str: Nearest occurances of the query string.\n    \"\"\"\n    formatted_response = rag_retriever(query)\n    \n    return formatted_response", "execution_count": 25, "outputs": []}, {"metadata": {}, "id": "39db5b60", "cell_type": "code", "source": "rag_tool = Tool(\n    name=\"milvus_retriever\",\n    func=milvus_retriever,\n    description=\"Search for information in the vector database.\",\n)", "execution_count": 26, "outputs": []}, {"metadata": {}, "id": "4a0b2ca8", "cell_type": "code", "source": "with get_ecommerce_db() as db:\n    if db is not None:\n        sql_toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n        tools_chat = sql_toolkit.get_tools()\n    else:\n        print(\"Failed to connect to the database.\")", "execution_count": 27, "outputs": []}, {"metadata": {}, "id": "ed83319b", "cell_type": "code", "source": "tools_chat.append(rag_tool)", "execution_count": 28, "outputs": []}, {"metadata": {}, "id": "e5e40843", "cell_type": "markdown", "source": "Furthermore, we define custom `CustomJSONAgentOutputParser` because sometimes model may return response with additional tokens before action JSON blob. "}, {"metadata": {}, "id": "d106000e", "cell_type": "code", "source": "from langchain.agents.output_parsers import JSONAgentOutputParser\nfrom langchain_core.agents import AgentAction, AgentFinish", "execution_count": 29, "outputs": []}, {"metadata": {}, "id": "e759c486", "cell_type": "code", "source": "class CustomJSONAgentOutputParser(JSONAgentOutputParser):\n    def parse(self, text: str) -> AgentAction | AgentFinish:\n        i = text.find(\"{\")\n\n        # Sometimes model may return additional tokens before json blob\n        text = text[i:]\n        if \"```\" not in text:\n            text = \"\\n```\\n\" + text\n        return super().parse(text + \"\\n```\\nObservation:\")", "execution_count": 30, "outputs": []}, {"metadata": {}, "id": "e0d44ad7", "cell_type": "markdown", "source": "<a id=\"agent\"></a>\n## Initialize an Agent"}, {"metadata": {}, "id": "87fab9a4", "cell_type": "markdown", "source": "Following section is the central part of the presented notebook. Here, we construct LangChain Agent and initialise `AgentExecutor` which manage conversation with AI assistant, that has access to the predefined tools, and human."}, {"metadata": {}, "id": "3e19415b", "cell_type": "code", "source": "from langchain_core.runnables import RunnablePassthrough\nfrom langchain.agents import AgentExecutor\nfrom langchain.tools.render import render_text_description\nfrom langchain.agents.format_scratchpad import format_log_to_str", "execution_count": 31, "outputs": []}, {"metadata": {}, "id": "872d95ea", "cell_type": "markdown", "source": "In the prompt template, we include the tools signature and their description."}, {"metadata": {}, "id": "27eda858", "cell_type": "code", "source": "prompt_chat = prompt.partial(\n    tools=render_text_description(list(tools_chat)),\n    tool_names=\", \".join([t.name for t in tools_chat]),\n)", "execution_count": 32, "outputs": []}, {"metadata": {}, "id": "d25ccb9b", "cell_type": "markdown", "source": "Finally, when we have all components prepared we can define Chat Agent and initialize `AgentExecutor`."}, {"metadata": {}, "id": "18e5c4bf", "cell_type": "code", "source": "# Setting stop sequence for LLM\nllm_with_stop = llm.bind(stop=[\"}\\n\"])\n\nagent_chat = (\n    RunnablePassthrough.assign(\n        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n    )\n    | prompt_chat\n    | llm_with_stop\n    | CustomJSONAgentOutputParser()\n)\n\nagent_executor_chat = AgentExecutor(\n    agent=agent_chat, tools=tools_chat, verbose=True, handle_parsing_errors=True, return_intermediate_steps=True\n)", "execution_count": 33, "outputs": []}, {"metadata": {}, "id": "531cf905", "cell_type": "markdown", "source": "Notice that we use `handle_parsing_errors=True` to ensure that when LLM is not able to determine what step to take because its output does not have the correct structure to be handled  by output parser, the user's input will be sent back to the model with the appropriate information to improve the model reponse. Setitng this parameter to True help to keep chat conversation smooth, but may also result in multiple requests with many tokens being sent to the model and back."}, {"metadata": {}, "id": "4a88674c", "cell_type": "markdown", "source": "<a id=\"chat\"></a>\n## Structured Chat with memory"}, {"metadata": {}, "id": "9e51754a", "cell_type": "markdown", "source": "To include chat memory in conversation with AI assistant we are going to use `ChatMessageHistory` that simply store chat history in the prompt and send it with every user question to the LLM. "}, {"metadata": {}, "id": "9bafe06c", "cell_type": "code", "source": "from langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory", "execution_count": 34, "outputs": []}, {"metadata": {}, "id": "23a50f80", "cell_type": "code", "source": "message_history = ChatMessageHistory()\n\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor_chat,\n    get_session_history=lambda session_id: message_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n)", "execution_count": 35, "outputs": []}, {"metadata": {}, "id": "d837e8a1", "cell_type": "code", "source": "import time", "execution_count": 36, "outputs": []}, {"metadata": {}, "id": "db3ded20", "cell_type": "code", "source": "def agentExecutorWithExecTime(input_text: str, session_id: str) -> dict:\n    start_time = time.time()\n    answer = agent_with_chat_history.invoke(\n        {\"input\": input_text},\n        config={\"configurable\": {\"session_id\": session_id}},\n    )\n    end_time = time.time()\n    execution_time = end_time - start_time\n    return {\n        \"input\": answer['input'],\n        \"chat_history\": answer['chat_history'],\n        \"output\": answer['output'],\n        \"execution_time\": f'{round(execution_time, 2)} sec'\n    }", "execution_count": 37, "outputs": []}, {"metadata": {"scrolled": true}, "id": "976cbc74", "cell_type": "code", "source": "agentExecutorWithExecTime(\"Which product did Alice buy?\", \"wx\")", "execution_count": 38, "outputs": [{"output_type": "stream", "text": "\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"sql_db_list_tables\",\n  \"action_input\": \"\"\n}\n\n```\nObservation:\u001b[0m\u001b[38;5;200m\u001b[1;3mcustomer_purchase_history, product_inventory, sales_data\u001b[0m\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"sql_db_schema\",\n  \"action_input\": \"customer_purchase_history, product_inventory, sales_data\"\n}\n\n```\nObservation:\u001b[0m\u001b[33;1m\u001b[1;3m\nCREATE TABLE customer_purchase_history (\n\tcustomerid SMALLINT, \n\tcustomername VARCHAR(7), \n\tproductid VARCHAR(4), \n\tpurchasedate DATE, \n\tquantity SMALLINT\n)\n\n/*\n3 rows from customer_purchase_history table:\ncustomerid\tcustomername\tproductid\tpurchasedate\tquantity\n101\tAlice\tP001\t2023-06-01\t2\n102\tBob\tP002\t2023-06-02\t1\n103\tCharlie\tP003\t2023-06-03\t1\n*/\n\n\nCREATE TABLE product_inventory (\n\tproductid VARCHAR(4), \n\tproductname VARCHAR(7), \n\tcategory VARCHAR(11), \n\tstock SMALLINT, \n\tprice DECIMAL(8, 2)\n)\n\n/*\n3 rows from product_inventory table:\nproductid\tproductname\tcategory\tstock\tprice\nP001\tiPhone\tPhones\t50\t999.99\nP002\tiPad\tTablets\t100\t329.99\nP003\tMac\tComputers\t30\t1199.99\n*/\n\n\nCREATE TABLE sales_data (\n\torderid SMALLINT, \n\tcustomerid SMALLINT, \n\tproductid VARCHAR(4), \n\tquantity SMALLINT, \n\tsaledate DATE, \n\ttotalprice DECIMAL(8, 2)\n)\n\n/*\n3 rows from sales_data table:\norderid\tcustomerid\tproductid\tquantity\tsaledate\ttotalprice\n1\t101\tP001\t2\t2023-06-01\t1999.98\n2\t102\tP002\t1\t2023-06-02\t329.99\n3\t103\tP003\t1\t2023-06-03\t1199.99\n*/\u001b[0m\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"sql_db_query_checker\",\n  \"action_input\": \"SELECT productname FROM product_inventory WHERE productid IN (SELECT productid FROM customer_purchase_history WHERE customername = 'Alice')\"\n}\n\n```\nObservation:\u001b[0m\u001b[36;1m\u001b[1;3m SELECT productname FROM product_inventory WHERE productid IN (SELECT productid FROM customer_purchase_history WHERE customername = 'Alice')\u001b[0m\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"sql_db_query\",\n  \"action_input\": \"SELECT productname FROM product_inventory WHERE productid IN (SELECT productid FROM customer_purchase_history WHERE customername = 'Alice')\"\n}\n\n```\nObservation:\u001b[0m\u001b[36;1m\u001b[1;3m[('iPhone',), ('AirPods',)]\u001b[0m\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Alice bought iPhone and AirPods.\"\n}\n\n```\nObservation:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 38, "data": {"text/plain": "{'input': 'Which product did Alice buy?',\n 'chat_history': [],\n 'output': 'Alice bought iPhone and AirPods.',\n 'execution_time': '11.18 sec'}"}, "metadata": {}}]}, {"metadata": {"scrolled": true}, "id": "90c37ff2-c66f-4d34-9f42-8a5ec2f802cc", "cell_type": "code", "source": "agentExecutorWithExecTime(\"What is her reaction to those products?\", \"wx\")", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"milvus_retriever\",\n  \"action_input\": \"Alice's reaction to iPhone and AirPods\"\n}\n\n```\nObservation:\u001b[0m\u001b[33;1m\u001b[1;3m[Document]\nMentionID: M003\nText: \"Just got the new Mac, and it's amazing! #apple #computers\"\nProductID: P003\nPlatform: Instagram\nName: Charlie\n\nMentionID: M004\nText: \"The AirPods have great sound quality. #apple #accessories\"\nProductID: P004\nPlatform: Instagram\nName: Alice\n\nMentionID: M005\nText: \"The new iPhone is impressive. Can't wait to explore all its features. #apple\"\nProductID: P001\nPlatform: Twitter\nName: David\n\nMentionID: M006\nText: \"iPad is my go-to device for reading and browsing. #apple #ipad\"\nProductID: P002\nPlatform: Facebook\nName: Frank\n\nMentionID: M007\nText: \"My new Mac is a powerhouse. Perfect for my design work. #apple #mac\"\nProductID: P003\nPlatform: Instagram\nName: Charlie\n\nMentionID: M008\nText: \"The AirPods' noise cancellation is top-notch. #apple #airpods\"\nProductID: P004\nPlatform: Twitter\nName: Alice\n\nMentionID: M009\nText: \"The iPhone camera is stunning. Captures amazing photos. #apple #iphone\"\nProductID: P001\nPlatform: Twitter\nName: Eve\n[End]\n\n[Document]\n## Customer Reviews\n\nReviewID: R001\nText: \"The iPhone is fantastic! Great build quality and very useful.\"\nProductID: P001\nSentiment: Positive\nName: Alice\n\nReviewID: R002\nText: \"The iPad is okay, but a bit overpriced for what it offers.\"\nProductID: P002\nSentiment: Neutral\nName: Bob\n\nReviewID: R003\nText: \"The Mac exceeded my expectations. Highly recommend it!\"\nProductID: P003\nSentiment: Positive\nName: Charlie\n\nReviewID: R004\nText: \"The AirPods are not as good as I expected. They broke after a week.\"\nProductID: P004\nSentiment: Negative\nName: Alice\n\nReviewID: R005\nText: \"The iPhone is great, but could be a bit cheaper.\"\nProductID: P001\nSentiment: Positive\nName: David\n\nReviewID: R006\nText: \"The iPad is very useful for my daily tasks.\"\nProductID: P002\nSentiment: Positive\nName: Bob\n\nReviewID: R007\nText: \"The Mac is simply the best computer I have ever used.\"\nProductID: P003\nSentiment: Positive\nName: Charlie\n[End]\u001b[0m\u001b[32;1m\u001b[1;3m\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Alice's reaction to the iPhone is positive, stating that it is fantastic with great build quality and very useful. However, her reaction to the AirPods is negative, mentioning that they are not as good as she expected and broke after a week.\"\n}\n\n```\nObservation:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 39, "data": {"text/plain": "{'input': 'What is her reaction to those products?',\n 'chat_history': [HumanMessage(content='Which product did Alice buy?'),\n  AIMessage(content='Alice bought iPhone and AirPods.')],\n 'output': \"Alice's reaction to the iPhone is positive, stating that it is fantastic with great build quality and very useful. However, her reaction to the AirPods is negative, mentioning that they are not as good as she expected and broke after a week.\",\n 'execution_time': '4.76 sec'}"}, "metadata": {}}]}, {"metadata": {}, "id": "fb33c420", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}
